{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Table of Contents  \n",
    "1  Resumen teórico  \n",
    "1.1  Definición formal  \n",
    "1.2  Funciones kernel  \n",
    "1.3  Outliers  \n",
    "1.4  Preprocesado de datos  \n",
    "1.4.1  Atributos categóricos  \n",
    "1.4.2  Escalado  \n",
    "1.5  Selección del modelo  \n",
    "1.6  Cross-validation  \n",
    "2  Notas a la implementación  \n",
    "3  Análisis del fichero s  \n",
    "3.1  Cargar los ficheros s-train/test  \n",
    "3.2  Seleccionar las 3 clases más frecuentes  \n",
    "3.3  Obtención de un clasificador MVS lineal en el espacio de parámetros  \n",
    "3.4  Realizar una búsqueda similar para núcleos polinómicos de grado 2  \n",
    "3.5  Obtención de un clasificador MVS lineal en el espacio proyectado mediante un núcleo gaussiano  \n",
    "4  Probar distintos tipos de nucleos con un problema no separable linealmente  \n",
    "4.1  Gausianas con escaso solape - separables linealmente  \n",
    "4.2  Gausianas fuertemente solapadas - no separables  \n",
    "4.3  Gausianas separables polinómicamente  \n",
    "5  Utilizar el resto de conjuntos y discutir los resultados  \n",
    "5.1  Conjunto c  \n",
    "5.2  Conjunto p  \n",
    "5.3  Conjunto v  \n",
    "5.4  Conjunto h  \n",
    "5.5  Conjunto z  \n",
    "5.6  Análisis de resultados en los conjuntos c, p, v, h y z  \n",
    "6  Referencias  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Resumen teórico\n",
    "\n",
    "El algoritmo de k-medias (en inglés k-means) es el algoritmo de clustering por vecindad más popular actualmente [3]. K-medias produce particiones de los\n",
    "datos, es decir, una vez aplicado los datos no pueden pertenecer a 2 categorías\n",
    "como por ejemplo en los algoritmos que generan particiones jerárquicas.\n",
    "\n",
    "K-medias parte de un estado inicial con una serie de patrones sin etiquetar y\n",
    "unos vectores cuyos valores han sido inicializados aleatoriamente que representarán cada una de las k categorías en las que queremos clasificar los patrones[2]. Cada vez que mostramos un nuevo patrón al algoritmo, es comparado con todos los vectores existentes (denominados centroides) y se etiquetará con la clase del centroide que esté a menor distancia del patrón.\n",
    "\n",
    "Por tanto ya hemos definido los parametros necesarios para ejecutar el algorimo\n",
    "k-medias:\n",
    "\n",
    "- Un conjunto de patrones de entrenamiento\n",
    "- Un núumero k en el que queremos particionar los datos.\n",
    "- Una métrica para medir la distancia entre los patrones (normalmente se utiliza la distancia euclidea)\n",
    "\n",
    "![k-means](k_means.png)\n",
    "\n",
    "*Figura 1: Ejemplo de entrenamiento del algoritmo K-medias para 2 clases*\n",
    "\n",
    "El proceso de entrenamiento se reduce a conseguir que los centroides sean\n",
    "puntos significativos para cada cluster k, esto se consigue de la siguiente forma:\n",
    "\n",
    "- Para cada patrón del conjutno de entrenamiento, calcular su prototipo más cercano y a~nadirlo a su lista de patrones.\n",
    "- Una vez introducidos todos los ejemplos, volver a calcular los valores de los centroides a partir de los patrones que pertenecen a su lista.\n",
    "- Repetir este proceso hasta que los centroides convergan (se estabilicen y no se muevan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante este proceso dividimos los patrones de entrenamiento en k regiones\n",
    "cada una con su prototipo en el centro. Aunque el proceso de entrenamiento\n",
    "puede ser largo, una vez entrenado el sitema clasificar patrones es inmediato, ya que sólo hay que calcular la distancia entre el patrón y los centroides y asignar el patrón al cluster del centroide más cercano.\n",
    "\n",
    "Dado que en la mayoría de casos en los que se utilizaría este algoritmo desconocemos la clase de los patrones, es difícil establecer métricas para medir la bondad del modelo obtenido.\n",
    "\n",
    "Si pensamos en k-medias como un clasificador, en el sentido de que patrones\n",
    "similares son etiquetados en la misma clase, un método sencillo para entender\n",
    "como se comporta el clasificador es utilizar una **matriz de confusión**[1].\n",
    "\n",
    "En una matriz de confusión la clase dada por el modelo está escrita en la\n",
    "parte superior mientras que la etiqueta real esta escrita en la parte derecha. Cada celda de la matriz cuenta cuantas instancias de la clase real han sido clasificadas en cada clase por lo que con esta matriz podemos ver de forma sencilla como de a menudo una clase es incorrectamente clasificada. Una clasificación perfecta produciría una matriz con todo ceros excepto la diagonal, mientras que una mala clasificación produciría valores elevados fuera de la diagonal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
