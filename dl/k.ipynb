{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# from keras.callbacks import TensorBoard\n",
    "\n",
    "# tb = TensorBoard(\n",
    "#     log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "# model.fit(X_train,\n",
    "#           Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           nb_epoch=nb_epoch,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test, Y_test),\n",
    "#           callbacks=[tb])\n",
    "# score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.preprocessing.image import load_img, list_pictures\n",
    "\n",
    "p = list_pictures('/home/ubuntu/ai/md/imagenesdepolen')[0]\n",
    "a = load_img(p, target_size=(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for p in list_pictures('/home/ubuntu/ai/md/imagenesdepolen'):\n",
    "#     i = load_img(p)\n",
    "#     print(float(i.height) / i.width)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# sorted(list_pictures('/home/ubuntu/ai/md/imagenesdepolen'),\n",
    "#        key=lambda p: load_img(p).height/load_img(p).width)    \n",
    "\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_17.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_22.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_29.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_31.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_35.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/arecaceae_04.jpg',\n",
    "#     ...\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/tridax_26.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/tridax_27.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/tridax_28.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/tridax_33.jpg',\n",
    "# '/home/ubuntu/ai/md/imagenesdepolen/syagrus_32.jpg'\n",
    "\n",
    "load_img('/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_17.jpg')\n",
    "# load_img('/home/ubuntu/ai/md/imagenesdepolen/syagrus_32.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Poner esto en titanpad/DeepLearning\n",
    "# Gracias Jesús.\n",
    "# La verdad que después de leer un poco sobre CNNs, teniendo en cuenta que tenemos pocas imágenes, para entrenar la red y para evitar sobreajuste parece que es conveniente generar nuevas imágenes aplicando ruido a las originales con una técnica que parece llamarse \"data augmentation\".\n",
    "# En este sentido estoy por pensar que el hecho de que las imágenes sean de distinto tamaño puede hasta haber sido una afortunada casualidad que nos haga reflexionar sobre el asunto.\n",
    "# O dicho de otro modo, las que sean cuadradas las podemos coger tal cual y aplicar el redimensionado al tamaño que decidamos para el shape del input, y las que no sean cuadradas las podemos \"trocear\" en cuadrados.\n",
    "# Por cierto, en relación a lo que comentabas sobre los posibles frameworks, yo la verdad que he empezado a jugar con Keras (y tensorflow como backend). Lo de tensorflow en lugar de theano era porque me llamada la atención el tensorboard, pero en vano porque en la máquina que hago las pruebas es tan pequeña que parece que se queda sin memoria.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, list_pictures\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "\n",
    "# p = list_pictures('/home/ubuntu/ai/md/imagenesdepolen')[0]\n",
    "\n",
    "# a = load_img('/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_16.jpg')\n",
    "\n",
    "a = load_img('/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_17.jpg')\n",
    "# a = load_img('/home/ubuntu/ai/md/imagenesdepolen/syagrus_32.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generador de carpetas de imágenes con train, test, validation 60-20-20\n",
    "# a partir de las imágenes originales\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, list_pictures\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "from itertools import groupby\n",
    "from random import shuffle\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=0)\n",
    "\n",
    "# from matplotlib.pyplot import plot\n",
    "\n",
    "# pictures = list_pictures('/home/ubuntu/ai/md/imagenesdepolen')\n",
    "\n",
    "def cut_up_picture(p):\n",
    "    \"\"\"\n",
    "    Dada una imagen, si es poco cuadrada\n",
    "    la devuelve en trozos cuadrados\n",
    "    \"\"\"\n",
    "#     if min(p.size) == max(p)\n",
    "    l = min(p.size)\n",
    "    p1 = p.crop((0, 0, l, l))\n",
    "    p2 = p.crop((p.width - l, p.height - l, p.width, p.height))\n",
    "    return p1, p2\n",
    "    \n",
    "def fold(pictures):\n",
    "    groups = groupby(pictures, lambda x: x.split(\"/\")[-1].split(\"_\")[0])\n",
    "    result = {'train':{},'test':{},'validation':{}}\n",
    "    for k, g in groups:\n",
    "        g = list(g)\n",
    "        shuffle(g)\n",
    "        a = int(round(len(g) * 0.6))\n",
    "        b = int(round(len(g) * 0.8))\n",
    "        result['train'][k] = g[:a]\n",
    "        result['test'][k] = g[a:b]\n",
    "        result['validation'][k] = g[b:]\n",
    "    return result\n",
    "\n",
    "    # a = load_img('/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_16.jpg')\n",
    "\n",
    "    # a = load_img('/home/ubuntu/ai/md/imagenesdepolen/anadenanthera_17.jpg')\n",
    "    # a = load_img('/home/ubuntu/ai/md/imagenesdepolen/syagrus_32.jpg')\n",
    "\n",
    "\n",
    "# n, g = groups.next()\n",
    "# g = list(g)\n",
    "\n",
    "# pp.pprint( fold(pictures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 16.0, 20)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
