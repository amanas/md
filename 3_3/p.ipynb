{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Máquinas-de-soporte-vectorial\" data-toc-modified-id=\"Máquinas-de-soporte-vectorial-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Máquinas de soporte vectorial</a></div><div class=\"lev2 toc-item\"><a href=\"#Resumen-teórico\" data-toc-modified-id=\"Resumen-teórico-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resumen teórico</a></div><div class=\"lev3 toc-item\"><a href=\"#Definición-formal\" data-toc-modified-id=\"Definición-formal-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Definición formal</a></div><div class=\"lev3 toc-item\"><a href=\"#Funciones-kernel\" data-toc-modified-id=\"Funciones-kernel-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Funciones kernel</a></div><div class=\"lev3 toc-item\"><a href=\"#Outliers\" data-toc-modified-id=\"Outliers-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Outliers</a></div><div class=\"lev3 toc-item\"><a href=\"#Preprocesado-de-datos\" data-toc-modified-id=\"Preprocesado-de-datos-114\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Preprocesado de datos</a></div><div class=\"lev4 toc-item\"><a href=\"#Atributos-categóricos\" data-toc-modified-id=\"Atributos-categóricos-1141\"><span class=\"toc-item-num\">1.1.4.1&nbsp;&nbsp;</span>Atributos categóricos</a></div><div class=\"lev4 toc-item\"><a href=\"#Escalado\" data-toc-modified-id=\"Escalado-1142\"><span class=\"toc-item-num\">1.1.4.2&nbsp;&nbsp;</span>Escalado</a></div><div class=\"lev3 toc-item\"><a href=\"#Selección-del-modelo\" data-toc-modified-id=\"Selección-del-modelo-115\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Selección del modelo</a></div><div class=\"lev3 toc-item\"><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-116\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;</span>Cross-validation</a></div><div class=\"lev2 toc-item\"><a href=\"#Notas-a-la-implementación\" data-toc-modified-id=\"Notas-a-la-implementación-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Notas a la implementación</a></div><div class=\"lev2 toc-item\"><a href=\"#Actividad-1:-análisis-del-fichero-S\" data-toc-modified-id=\"Actividad-1:-análisis-del-fichero-S-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Actividad 1: análisis del fichero S</a></div><div class=\"lev3 toc-item\"><a href=\"#Cargar-los-ficheros-s-train/test\" data-toc-modified-id=\"Cargar-los-ficheros-s-train/test-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Cargar los ficheros s-train/test</a></div><div class=\"lev3 toc-item\"><a href=\"#Seleccionar-las-3-clases-más-frecuentes\" data-toc-modified-id=\"Seleccionar-las-3-clases-más-frecuentes-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Seleccionar las 3 clases más frecuentes</a></div><div class=\"lev3 toc-item\"><a href=\"#Obtención-de-un-clasificador-MVS-lineal-en-el-espacio-de-parámetros\" data-toc-modified-id=\"Obtención-de-un-clasificador-MVS-lineal-en-el-espacio-de-parámetros-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Obtención de un clasificador MVS lineal en el espacio de parámetros</a></div><div class=\"lev3 toc-item\"><a href=\"#Realizar-una-búsqueda-similar-para-núcleos-polinómicos-de-grado-2\" data-toc-modified-id=\"Realizar-una-búsqueda-similar-para-núcleos-polinómicos-de-grado-2-134\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Realizar una búsqueda similar para núcleos polinómicos de grado 2</a></div><div class=\"lev3 toc-item\"><a href=\"#Obtención-de-un-clasificador-MVS-lineal-en-el-espacio-proyectado-mediante-un-núcleo-gaussiano\" data-toc-modified-id=\"Obtención-de-un-clasificador-MVS-lineal-en-el-espacio-proyectado-mediante-un-núcleo-gaussiano-135\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Obtención de un clasificador MVS lineal en el espacio proyectado mediante un núcleo gaussiano</a></div><div class=\"lev2 toc-item\"><a href=\"#Actividad-2:-Probar-distintos-tipos-de-nucleos-con-un-problema-no-separable-linealmente\" data-toc-modified-id=\"Actividad-2:-Probar-distintos-tipos-de-nucleos-con-un-problema-no-separable-linealmente-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Actividad 2: Probar distintos tipos de nucleos con un problema no separable linealmente</a></div><div class=\"lev2 toc-item\"><a href=\"#Utilizar-el-resto-de-conjuntos-y-discutir-los-resultados\" data-toc-modified-id=\"Utilizar-el-resto-de-conjuntos-y-discutir-los-resultados-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Utilizar el resto de conjuntos y discutir los resultados</a></div><div class=\"lev2 toc-item\"><a href=\"#Referencias\" data-toc-modified-id=\"Referencias-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Referencias</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de soporte vectorial\n",
    "\n",
    "1. Resumen teórico 0,313\n",
    "2. Objetivo 0,313\n",
    "3. Figuras de la técnica (separadores) 0,313\n",
    "4. Referencias 0,313\n",
    "5. Sobreajuste 0,625\n",
    "6. Kernel Trick 0,313\n",
    "7. Cross-Validation 0,313\n",
    "8. Estudio 1,875\n",
    "9. Estudio 1,875\n",
    "10. Estudio 3,750\n",
    "11. Estudio 1,250\n",
    "12. Estudio 1,250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen teórico\n",
    "\n",
    "Las máquinas de soporte vectorial son un tipo de algoritmos utilizados principalmente para clasificación y para regresión desarollados por Vladimir Vapnik y su equipo [1].\n",
    "\n",
    "Las máquinas de soporte vectorial funcionan generando un hiperplano que separa el espacio de muestras de forma que, idealmente, patrones de diferentes clases nunca aparezcan en el mismo lado del plano. Como existen infinitos hiperplanos que separen el espacio, se busca aquel cuya distancia entre el hiperplano y los patrones de cada clase sea la máxima posible (ver Figura 1). A los puntos que conforman las dos líneas paralelas al hiperplano, siendo la distancia entre ellas (margen) la mayor posible, se les denomina vectores de soporte. En la fase de entrenamiento de las máquinas de soporte vectorial, nos centraremos en hallar los vectores de soporte empleando técnicas de programación cuadrática [3].\n",
    "\n",
    "Una vez obtenemos el hiperplano podemos utilizar la Máquina en problemas de clasificación, escogiendo patrones que no hayan sido vistos durante la fase de entrenamiento, y aplicando una etiqueta (clase) en función del lado del hiperplano en el que se proyecten.\n",
    "\n",
    "![\"Representación básica de SVM\"](esquema-basico-svm.PNG)\n",
    "*Figura 1: Ejemplo de 2 dimensiones para una máquina de soporte vectorial, obsérvese que la recta roja es la que maximiza la distancia entre los vectores de soporte (los puntos en amarillo)*\n",
    "\n",
    "\n",
    "\n",
    "Los universos a estudiar no se suelen presentar en casos idílicos de dos dimensiones como en el ejemplo anterior, sino que un algoritmo SVM debe tratar con:\n",
    "\n",
    "- Más de dos variables predictoras\n",
    "- Curvas no lineales de separación\n",
    "- Casos donde los conjuntos de datos no pueden ser completamente separados\n",
    "- Clasificaciones en más de dos categorías\n",
    "\n",
    "![\"Patrones no separables linealmente\"](no-separable-linealmente.PNG)\n",
    "*Figura 2: Espacio de 2 dimensiones en el que los patrones no son separables linealmente*\n",
    "\n",
    "### Definición formal\n",
    "\n",
    "> Dado un conjunto de entrenamiento formado por pares de instancias y etiquetas\n",
    "$$(x_i,y_i),  i=1, . . . , l \\text{ donde } x_i \\in R^n, y \\in \\{1, −1\\}^l$$\n",
    ", las SVMs pueden entenderse como la solución al siguiente problema de optimización::\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{w,b,\\epsilon}{\\operatorname{argmin}} & & \\frac{1}{2}w^Tw + C\n",
    "\\sum_1^l{\\epsilon_i} \\\\\n",
    "\\text{sujeto a} & & y_i(w^T \\phi(x_i) + b) \\ge 1- \\epsilon_i \\\\\n",
    " & & \\epsilon_i \\ge 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "Además, $K(x_i, x_j ) ≡ \\phi(x_i)^T \\phi(x_j)$ es llamada la función kernel.\n",
    "\n",
    "*Figura 3. Definición formal de las SVMs según [4]*\n",
    "\n",
    "Los vectores de entrenamiento $x_i$ son asignados a un espacio de mayor dimensiones (incluso infinitas) por la función $\\phi$. La máquina de soporte vectorial encuentra el hiperplano con máximo margen de separación en el espacio dimensional superior. C > 0 es el parámetro de penalización del término de error.\n",
    "\n",
    "### Funciones kernel\n",
    "\n",
    "Cuando el espacio donde trabajamos no permite separar linealmente los patrones de forma perfecta, como se puede observar en la figura 2, es imposible trazar un hiperplano que separe perfectamente los patrones. \n",
    "\n",
    "Por ello entran en juego las llamadas **funciones kernel**, funciones matemáticas que nos permiten proyectar los patrones en un espacio de mayor dimensión que el original dónde estos si son linealmente separables mediante un hiperplano (Figura 3). \n",
    "\n",
    "![\"Kernel de 2 a 3 dimensiones\"](ejemplo-kernel.PNG)\n",
    "*Figura 4: Kernel de 2 a 3 dimensiones dónde los patrones pueden ser perfectamente separados mediante un hiperplano*\n",
    "\n",
    "De nuevo, y como en la gran mayoría de algoritmos de aprendizaje máquina, **si elegimos un modelo (en este caso una función kernel) que se ajuste demasiado bien a los patrones de entrenamiento**, el clasificador perderá capacidad de generalización por lo que tendrá un mal comportamiento ante nuevos patrones y se hablará de **sobreentrenamiento**.\n",
    "\n",
    "Las funciones kernel más comunmente utilizadas son:\n",
    "\n",
    "- lineales: $K(x_i,x_j) = x_i^T x_j$\n",
    "- polinómicas: $K(x_i,x_j) = (\\gamma x_i^T x_j +r)^d, \\gamma \\ge 0$\n",
    "- funciones de base radial (RBF): $K(x_i,x_j) = exp(-\\gamma \\lVert x_i - x_j \\lVert ^2), \\gamma \\ge 0$\n",
    "- sigmoide: $K(x_i,x_j) = \\tanh(\\gamma x_i^T x_j +r) $\n",
    "\n",
    "\n",
    "### Outliers\n",
    "\n",
    "No siempre es posible encontrar una transformación de los datos que permita separarlos linealmente [2] o incluso a veces, no es conveniente.\n",
    "\n",
    "En este caso nos encontramos con instancias en el conjunto de entrenamiento que se situan en lugares del espacio muy separados o aislados de la zona dónde se sitúan la mayoría de instancias de entrenamiento con las que comparten la clase.\n",
    "\n",
    "La presencia de ruido o de **outliers** pueden llegar tambien a provocar soluciones sobreajustadas a los patrones de entrenamiento que no generalizan bien. Para tratar con estas situaciones se crearon los llamados **SVM de margen blando** cuya idea principal es introducir una holgura al margen existente entre los vectores de soporte y el hiperplano que permite que las restricciones no se cumplan de manera estricta. \n",
    "\n",
    "Se introduce por tanto en el proceso de entrenamiento una constante **C** que controlará el tamaño de la holgura.\n",
    "\n",
    "**El parámetro C le indica a la SVM, en el proceso de entrenamiento, el grado de ejemplos mal clasificados permitido.** \n",
    "\n",
    "Para valores grandes de C, la optimización elegirá un hiperplano de margen más pequeño si ese hiperplano hace un mejor trabajo para conseguir que todos los puntos de entrenamiento estén clasificados correctamente. Es decir, se evitan en mayor medida ejemplos mal clasificados aunque ello conduzca a hiperplanos de margen menor.\n",
    "\n",
    "Por el contrario, un valor muy pequeño de C hará que el optimizador busque un hiperplano de separación de mayor margen, incluso si ese hiperplano clasifica erróneamente más puntos. Para valores muy pequeños de C frecuentemente se obtienen ejemplos mal clasificados,  incluso si los datos de entrenamiento son linealmente separables. Sin embargo, el sobreajuste del clasificador es menor y generalmente se obtienen clasificadores que generalizan mejor.\n",
    "\n",
    "### Preprocesado de datos\n",
    "\n",
    "Se suele realizar a dos niveles [4]:\n",
    "\n",
    "#### Atributos categóricos\n",
    "\n",
    "Las SVMs requieren que cada instancia de datos se represente como un vector de números reales. Por lo tanto, si hay atributos categóricos, primero tenemos que convertirlos en datos numéricos. Se recomienda utilizar m números para representar un atributo con m categorías. Solamente uno de los m números es uno, y los otros son cero. Por ejemplo, una categoría de tres atributos como {rojo, verde, azul} puede representarse como (0,0,1), (0,1,0) y (1,0,0).\n",
    "\n",
    "La experiencia indica que si el número de valores en un atributo no es demasiado grande, esta codificación puede ser más estable que usar un solo número.\n",
    "\n",
    "#### Escalado\n",
    "\n",
    "Escalar los datos antes de aplicar las SVMs es muy importante. La mayoría de las consideraciones hechas para redes neuronales también se aplican a las SVMs. \n",
    "\n",
    "La principal ventaja de escalar es evitar que atributos cuyos valores se mueven en rangos numéricos altos dominen a aquellos que se mueven en rangos numéricos más pequeños. Otra ventaja es evitar dificultades numéricas durante el cálculo, dado que los valores del kernel normalmente dependen de los productos internos de vectores de características, p. \n",
    "\n",
    "Se recomienda un escalado lineal de cada atributo al rango [-1, +1] o [0, 1]. Por supuesto, hay usar el mismo método para escalar el los datos de entrenamiento y los de prueba.\n",
    "\n",
    "### Selección del modelo\n",
    "\n",
    "Aunque sólo son cuatro las funciones kernel más comunes, se debe decidir una para entrenar la SVM. Una vez elegido el núcleo, se ajustan los parámetros de penalización C y los parámetros propios del kernel elegido.\n",
    "\n",
    "**Según [4], en general, el núcleo RBF es una primera opción razonable.** \n",
    "\n",
    "Este kernel no correlaciona las muestras en un espacio dimensional superior, a diferencia del núcleo lineal, con lo que se puede manejar el caso cuando la relación entre las etiquetas y los atributos no es lineal. Además, el núcleo lineal es un caso especial de RBF.\n",
    "\n",
    "La segunda razón es el número de hiperparámetros que influyen en la complejidad de la selección del modelo. El núcleo polinomial tiene más hiperparametros que el núcleo RBF.\n",
    "\n",
    "Por último, el núcleo RBF tiene menos dificultades numéricas ya que el resultado  de aplicar la función kernel es siempre menor que 1.\n",
    "\n",
    "Hay algunas situaciones en las que el núcleo RBF no es adecuado. En particular, cuando el número de características es muy grande, se puede utilizar el núcleo lineal.\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Hay dos parámetros para un núcleo RBF: ** C y $\\gamma$ **. No se sabe de antemano que C y $\\gamma$ son los mejores para un problema dado. En consecuencia, algún tipo de estrategia de selección de parámetros debe realizarse. El objetivo es identificar los parámetros C y $\\gamma$ que generen el modelo que mejor clasifique nuestros datos. El proceso de encontrar estos parámetros consiste la fase de entrenamiento de la SVM.\n",
    "\n",
    "Con la técnica de validación cruzada, primero dividimos el conjunto de entrenamiento en v subconjuntos de igual tamaño. Secuencialmente, el modelo se entrena en $v-1$ subconjuntos y se valida el el restante subconjunto. El método de validación cruzada ayuda e prevenir el problema del sobreajuste, pues todas las instancias acaban siendo usadas para entrenamiento y para validación, alternativamente.\n",
    "\n",
    "## Notas a la implementación\n",
    "\n",
    "En el enunciado de la práctica se hace mención explícita a WEKA y a Torch.\n",
    "\n",
    "Sin embargo, entiendo que el lenguaje o la herramienta con la que resuelvan las prácticas es libre y las referencias a WEKA es simplemente por tener una herramienta por defecto para quien no tenga otras preferencias.\n",
    "\n",
    "En este sentido, y espero no estar cometiendo un error, me tomo la libertad de desarrollar esta práctica con python utilizando scikit-learn como librería de machine-learning.\n",
    "\n",
    "## Actividad 1: análisis del fichero S\n",
    "\n",
    "### Cargar los ficheros s-train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "\n",
    "S_train,S_meta = loadarff('svm-data/s-train.arff')\n",
    "S_test,_       = loadarff('svm-data/s-test.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar las 3 clases más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 classes: ['46', '20', '110']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = np.concatenate((S_train['class'],S_test['class']))\n",
    "class_counts = dict(zip(*np.unique(classes,return_counts=True)))\n",
    "top_three = sorted(class_counts, key=class_counts.get, reverse=True)[0:3]\n",
    "\n",
    "print 'Top 3 classes: %s' % top_three\n",
    "\n",
    "S_top3_train = S_train[np.in1d(S_train['class'], top_three)]\n",
    "S_top3_test  = S_test[np.in1d(S_test['class'], top_three)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de un clasificador MVS lineal en el espacio de parámetros\n",
    "\n",
    "Vamos a realizar una búsqueda en el espacio de parámetros para seleccionar el que produce mejores resultados\n",
    "evaluados mediante validación cruzada. \n",
    "\n",
    "Probaremos N valores del parámetro **C** equiespaciados entre dos valores A y B. Empezaremos con exploraciones con valores de N pequeños (2 o 3). Cuando tengamos una idea aproximada del tiempo empleado en cada exploración, ampliaremos el valor de N si lo creemos oportuno.\n",
    "\n",
    "Valores orientativos para el inicio pueden ser diversos rangos pequeños alrededor de 0.001, 0.01, 0.1,1 y 10.\n",
    "\n",
    "Obsérvese que la función cross_val_score entrena y evalúa un estimador por validación cruzada, devolviendo un array por ronda de la puntuación obtenida por el estimador en cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001:  \t[ 0.6         0.8         0.8         0.8         0.76923077]\n",
      "C = 0.01:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.1:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 1:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 10:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = S_top3_train[S_meta.names()[:-1]].reshape(-1, 1)\n",
    "y = S_top3_train['class']\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    model = svm.SVC(kernel='linear', C=C)\n",
    "    print 'C = %s:  \\t%s' % (C,cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los mejores resultados se obtienen cuando C adopta valores pequeños, es decir, para MVS de margen blando.\n",
    "\n",
    "Vemos además que otros valores de C alrededor de 0.001 no mejoran sustancialmente los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001:  \t[ 0.6         0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0006:  \t[ 0.6         0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0011:  \t[ 0.6         0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0016:  \t[ 0.6         0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0021:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0026:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0031:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0036:  \t[ 0.46666667  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0041:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0046:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0051:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.0056:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0061:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0066:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0071:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0076:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0081:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0086:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0091:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n",
      "C = 0.0096:  \t[ 0.53333333  0.8         0.8         0.8         0.61538462]\n"
     ]
    }
   ],
   "source": [
    "for C in np.arange(0.0001,0.01,0.0005):\n",
    "    model = svm.SVC(kernel='linear', C=C)\n",
    "    print 'C = %s:  \\t%s' % (C,cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como obtenemos algunas máquinas con unos errores de clasificación en torno al 0.76%, podemos sospechar que el problema sí es linealmente separable.**\n",
    "\n",
    "Podemos evaluar entonces el resultado de entrenar una MVS con C=0.001 en nuestro conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66386554621848737"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = S_top3_test[S_meta.names()[:-1]].reshape(-1, 1)\n",
    "y_test = S_top3_test['class']\n",
    "model = svm.SVC(kernel='linear', C=0.001).fit(X,y)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar una búsqueda similar para núcleos polinómicos de grado 2\n",
    "\n",
    "Procedemos de forma similar al punto anterior, pero en este caso utilizando una función kernel de tipo polinómica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.01:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 0.1:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 1:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n",
      "C = 10:  \t[ 0.53333333  0.8         0.8         0.8         0.76923077]\n"
     ]
    }
   ],
   "source": [
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    model = svm.SVC(kernel='poly', degree=2, C=C)\n",
    "    print 'C = %s:  \\t%s' % (C,cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados no son mejores que en la caso de un kernel lineal. \n",
    "\n",
    "### Obtención de un clasificador MVS lineal en el espacio proyectado mediante un núcleo gaussiano\n",
    "\n",
    "Repetimos los pasos del apartado anterior incluyendo en la ventana de parámetros explorados dos entradas, una para el parámetro C y otra para G (gamma) del núcleo gaussiano o de base radial. \n",
    "\n",
    "Para facilitar el procedimiento, comenzamos fijando un rango alrededor del valor óptimo de C obtenido en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0005, G=0.001:  \t[ 0.4         0.4         0.4         0.4         0.76923077]\n",
      "C = 0.0005, G=0.01:  \t[ 0.4         0.4         0.4         0.4         0.61538462]\n",
      "C = 0.0005, G=0.1:  \t[ 0.4         0.4         0.4         0.4         0.53846154]\n",
      "C = 0.0005, G=1:  \t[ 0.4         0.4         0.4         0.4         0.38461538]\n",
      "C = 0.001, G=0.001:  \t[ 0.4         0.4         0.4         0.4         0.76923077]\n",
      "C = 0.001, G=0.01:  \t[ 0.4         0.4         0.4         0.4         0.61538462]\n",
      "C = 0.001, G=0.1:  \t[ 0.4         0.4         0.4         0.4         0.53846154]\n",
      "C = 0.001, G=1:  \t[ 0.4         0.4         0.4         0.4         0.38461538]\n",
      "C = 0.005, G=0.001:  \t[ 0.4         0.4         0.4         0.4         0.76923077]\n",
      "C = 0.005, G=0.01:  \t[ 0.4         0.4         0.4         0.4         0.61538462]\n",
      "C = 0.005, G=0.1:  \t[ 0.4         0.4         0.4         0.4         0.53846154]\n",
      "C = 0.005, G=1:  \t[ 0.4         0.4         0.4         0.4         0.38461538]\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.0005, 0.001, 0.005]\n",
    "Gs = [0.001, 0.01, 0.1, 1]\n",
    "for C in Cs:\n",
    "    for G in Gs:\n",
    "        model = svm.SVC(kernel='rbf', C=C, gamma=G)\n",
    "        print 'C = %s, G=%s:  \\t%s' % \\\n",
    "              (C,G,cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los mejores resultados se encuentran con valores de gamma muy pequeños, aunque siempre son peores que los que se encontraron en el caso del núcleo lineal. **Esto puede ser síntoma de que se está produciendo sobreajuste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad 2: Probar distintos tipos de nucleos con un problema no separable linealmente\n",
    "\n",
    "Genere un conjunto de entrenamiento con dos atributos, no separable linealmente. Por ejemplo, utilice dos distribuciones de probabilidad gaussianas para cada clase y simule el problema XOR. Pruebe distintos tipos de núcleo y analice y discuta los resultados ayudándose de gráficas.\n",
    "\n",
    "Puede variar los parámetros de las gaussianas aumentando o disminuyendo las regiones de solape entre clases y estudiar el valor óptimo de los parámetros en función del tamaño de las regiones de confusión.\n",
    "\n",
    "Primero generamos un conjunto de datos, donde las dos primeras columnas son valores normales aleatorios y la tercera es el XOR de las dos primeras (True si tienen distinto signo, False si no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = np.array([[x,y,x*y <= 0] for x,y in np.random.normal(size=(3000,2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que nos permita dibujar los datos anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff400c52b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_data(data):\n",
    "    trues = data[data[:,2] == True]\n",
    "    plt.plot(trues[:,0], trues[:,1], 'bo')\n",
    "    falses = data[data[:,2] == False]\n",
    "    plt.plot(falses[:,0], falses[:,1], 'ro')\n",
    "    plt.show()\n",
    "\n",
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y obserbamos que, gráficamente, el conjunto de datos no es linealmente separable. \n",
    "\n",
    "Vamos a ver que resultados brinda una MSV lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.499"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:2000,:-1]\n",
    "y_train = data[:2000,-1]\n",
    "X_test = data[2000:,:-1]\n",
    "y_test = data[2000:,-1]\n",
    "\n",
    "svm.SVC(kernel='linear').fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habida cuenta de que sólo tenemos dos clases, vemos que la clasificación es peor que elegir la clase aleatoriamente. Es decir, no es linealmente separable.\n",
    "\n",
    "Veamos con un kernel polinómico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50700000000000001"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC(kernel='poly').fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la configuración por defecto vemos que obtenemos pésimos resultados igualmente. Sin embargo, la configuración por defecto toma como grado de los polinomios 3. Veamos si probamos con polinomios de grado 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97399999999999998"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='poly', degree=2).fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchísimo mejor, casi una clasificación perfecta. Podemos dibujar las áreas en las que separa el espacio original la función kernel, que efectivamente se correponden con la distribución que adoptaban nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOVgCN34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff400c49890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_decision_function(clf, X, y):\n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.title('2-Class classification using Support Vector Machine')\n",
    "    plt.axis('tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_function(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizar el resto de conjuntos y discutir los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "[1] Corinna Cortes and Vladimir Vapnik. Support-vector networks. *Machine\n",
    "learning, 20(3):273–297, 1995.*\n",
    "\n",
    "[2] José Hernández Orallo and Mª José Ramírez Quintana. *Introducción a la\n",
    "Minería de Datos.*\n",
    "\n",
    "[3] Qiang Wu and Ding-Xuan Zhou. Svm soft margin classifiers: linear programming\n",
    "versus quadratic programming. *Neural computation, 17(5):1160–1187,\n",
    "2005.*\n",
    "\n",
    "[4] http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
